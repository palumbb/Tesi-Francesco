[2024-10-27 16:32:56,139][flwr][WARNING] - Both server and strategy were provided, ignoring strategy
[2024-10-27 16:32:56,139][flwr][INFO] - Starting Flower simulation, config: num_rounds=10, no round_timeout
[2024-10-27 16:33:05,321][flwr][INFO] - Flower VCE: Ray initialized with resources: {'CPU': 8.0, 'node:__internal_head__': 1.0, 'node:127.0.0.1': 1.0, 'object_store_memory': 633651609.0, 'memory': 1267303220.0}
[2024-10-27 16:33:05,321][flwr][INFO] - Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html
[2024-10-27 16:33:05,321][flwr][INFO] - Flower VCE: Resources for each Virtual Client: {'num_cpus': 4, 'num_gpus': 0.0}
[2024-10-27 16:33:05,353][flwr][INFO] - Flower VCE: Creating VirtualClientEngineActorPool with 2 actors
[2024-10-27 16:33:05,354][flwr][INFO] - [INIT]
[2024-10-27 16:33:05,355][flwr][INFO] - Requesting initial parameters from one random client
[2024-10-27 16:33:11,169][flwr][INFO] - Received initial parameters from one random client
[2024-10-27 16:33:11,171][flwr][INFO] - Starting evaluation of initial global parameters
[2024-10-27 16:33:11,211][flwr][ERROR] - Target is multilabel-indicator but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted', 'samples'].
[2024-10-27 16:33:11,230][flwr][ERROR] - Traceback (most recent call last):
  File "C:\Users\Riccardo\miniconda3\envs\flower\Lib\site-packages\flwr\simulation\app.py", line 339, in start_simulation
    hist = run_fl(
           ^^^^^^^
  File "C:\Users\Riccardo\miniconda3\envs\flower\Lib\site-packages\flwr\server\server.py", line 492, in run_fl
    hist, elapsed_time = server.fit(
                         ^^^^^^^^^^^
  File "C:\Users\Riccardo\miniconda3\envs\flower\Lib\site-packages\flwr\server\server.py", line 95, in fit
    res = self.strategy.evaluate(0, parameters=self.parameters)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Riccardo\miniconda3\envs\flower\Lib\site-packages\flwr\server\strategy\fedavg.py", line 167, in evaluate
    eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Riccardo\Desktop\PoliMi\Tesi-Francesco\servers\server_scaffold.py", line 255, in evaluate
    loss, accuracy, f1_score = test_binary(net, testloader, device=device)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Riccardo\Desktop\PoliMi\Tesi-Francesco\model\binarynet.py", line 390, in test_binary
    f1 = f1_score(all_targets, all_predictions, average='binary')
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Riccardo\miniconda3\envs\flower\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Riccardo\miniconda3\envs\flower\Lib\site-packages\sklearn\metrics\_classification.py", line 1293, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Riccardo\miniconda3\envs\flower\Lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Riccardo\miniconda3\envs\flower\Lib\site-packages\sklearn\metrics\_classification.py", line 1485, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Riccardo\miniconda3\envs\flower\Lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Riccardo\miniconda3\envs\flower\Lib\site-packages\sklearn\metrics\_classification.py", line 1789, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Riccardo\miniconda3\envs\flower\Lib\site-packages\sklearn\metrics\_classification.py", line 1578, in _check_set_wise_labels
    raise ValueError(
ValueError: Target is multilabel-indicator but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted', 'samples'].

[2024-10-27 16:33:11,245][flwr][ERROR] - Your simulation crashed :(. This could be because of several reasons. The most common are: 
	 > Sometimes, issues in the simulation code itself can cause crashes. It's always a good idea to double-check your code for any potential bugs or inconsistencies that might be contributing to the problem. For example: 
		 - You might be using a class attribute in your clients that hasn't been defined.
		 - There could be an incorrect method call to a 3rd party library (e.g., PyTorch).
		 - The return types of methods in your clients/strategies might be incorrect.
	 > Your system couldn't fit a single VirtualClient: try lowering `client_resources`.
	 > All the actors in your pool crashed. This could be because: 
		 - You clients hit an out-of-memory (OOM) error and actors couldn't recover from it. Try launching your simulation with more generous `client_resources` setting (i.e. it seems {'num_cpus': 4, 'num_gpus': 0.0} is not enough for your run). Use fewer concurrent actors. 
		 - You were running a multi-node simulation and all worker nodes disconnected. The head node might still be alive but cannot accommodate any actor with resources: {'num_cpus': 4, 'num_gpus': 0.0}.
Take a look at the Flower simulation examples for guidance <https://flower.ai/docs/framework/how-to-run-simulations.html>.
